<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-tutorial-extras/ceritfai-basics/interpret-scan-results" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Interpret Scan Results | Susan Michalski - Documentation Specialist</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://smichalski17-dev.github.io/documentarian/img/typwriter.jpg"><meta data-rh="true" name="twitter:image" content="https://smichalski17-dev.github.io/documentarian/img/typwriter.jpg"><meta data-rh="true" property="og:url" content="https://smichalski17-dev.github.io/documentarian/docs/tutorial-extras/ceritfai-basics/interpret-scan-results"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Interpret Scan Results | Susan Michalski - Documentation Specialist"><meta data-rh="true" name="description" content="This page provides illustrative examples of how to interpret scan results displayed in the Certifai Console.
"><meta data-rh="true" property="og:description" content="This page provides illustrative examples of how to interpret scan results displayed in the Certifai Console.
"><link data-rh="true" rel="canonical" href="https://smichalski17-dev.github.io/documentarian/docs/tutorial-extras/ceritfai-basics/interpret-scan-results"><link data-rh="true" rel="alternate" href="https://smichalski17-dev.github.io/documentarian/docs/tutorial-extras/ceritfai-basics/interpret-scan-results" hreflang="en"><link data-rh="true" rel="alternate" href="https://smichalski17-dev.github.io/documentarian/docs/tutorial-extras/ceritfai-basics/interpret-scan-results" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Documents","item":"https://smichalski17-dev.github.io/documentarian/docs/category/documents"},{"@type":"ListItem","position":2,"name":"Interpret Scan Results","item":"https://smichalski17-dev.github.io/documentarian/docs/tutorial-extras/ceritfai-basics/interpret-scan-results"}]}</script><link rel="alternate" type="application/rss+xml" href="/documentarian/blog/rss.xml" title="Susan Michalski - Documentation Specialist RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/documentarian/blog/atom.xml" title="Susan Michalski - Documentation Specialist Atom Feed"><link rel="stylesheet" href="/documentarian/assets/css/styles.6d484712.css">
<script src="/documentarian/assets/js/runtime~main.9d40e250.js" defer="defer"></script>
<script src="/documentarian/assets/js/main.ce0b64b7.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/documentarian/img/avatar.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/documentarian/"><div class="navbar__logo"><img src="/documentarian/img/avatar.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/documentarian/img/avatar.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/documentarian/docs/intro">Documentation</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/documentarian/docs/intro"><span title="Documentaion Samples" class="linkLabel_WmDU">Documentaion Samples</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/documentarian/docs/category/about-me"><span title="About Me" class="categoryLinkLabel_W154">About Me</span></a><button aria-label="Expand sidebar category &#x27;About Me&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/documentarian/docs/category/documents"><span title="Documents" class="categoryLinkLabel_W154">Documents</span></a><button aria-label="Collapse sidebar category &#x27;Documents&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/documentarian/docs/tutorial-extras/ceritfai-basics/factors/atx"><span title="ceritfai-basics" class="categoryLinkLabel_W154">ceritfai-basics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/documentarian/docs/tutorial-extras/ceritfai-basics/factors/atx"><span title="factors" class="categoryLinkLabel_W154">factors</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/documentarian/docs/tutorial-extras/ceritfai-basics/interpret-scan-results"><span title="Interpret Scan Results" class="linkLabel_WmDU">Interpret Scan Results</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/documentarian/docs/tutorial-extras/kubernetes-installation"><span title="Kubernetes Installation" class="linkLabel_WmDU">Kubernetes Installation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/documentarian/docs/tutorial-extras/monitoring-dashboard"><span title="Monitoring Dashboard" class="linkLabel_WmDU">Monitoring Dashboard</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/documentarian/docs/category/templates"><span title="Templates" class="categoryLinkLabel_W154">Templates</span></a><button aria-label="Expand sidebar category &#x27;Templates&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/documentarian/docs/category/cool-stuff"><span title="Cool Stuff" class="categoryLinkLabel_W154">Cool Stuff</span></a><button aria-label="Expand sidebar category &#x27;Cool Stuff&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/documentarian/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/documentarian/docs/category/documents"><span>Documents</span></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">ceritfai-basics</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Interpret Scan Results</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Interpret Scan Results</h1></header><p>This page provides illustrative examples of how to interpret scan results displayed in the Certifai Console.</p>
<p>Certifai scan results can offer significant information to model developers and business owners who have wider insights into the model. These insights can be used to steer subsequent model enhancements based on Certifai scores and explanations.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">​</a></h2>
<p>The discussion below assumes a working knowledge of the what trust factors are and how they are derived by counterfactuals. Read the pages related to trust factors before proceeding.</p>
<ul>
<li class=""><a class="" href="/documentarian/docs/tutorial-extras/ceritfai-basics/factors/performance-metric">Performance Metrics</a></li>
<li class=""><a class="" href="/documentarian/docs/tutorial-extras/ceritfai-basics/factors/fairness">Fairness</a></li>
<li class=""><a class="" href="/documentarian/docs/tutorial-extras/ceritfai-basics/factors/explainability">Explainability and Explanations</a></li>
<li class=""><a class="" href="/documentarian/docs/tutorial-extras/ceritfai-basics/factors/atx">ATX</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="assumptions">Assumptions<a href="#assumptions" class="hash-link" aria-label="Direct link to Assumptions" title="Direct link to Assumptions" translate="no">​</a></h2>
<ul>
<li class="">Interpretation is being done by someone with understanding of the domain and models</li>
<li class="">Explanation dataset has been taken as a representative sample</li>
<li class="">The models used for the examples that follow have not been optimized</li>
<li class="">The datasets used in the examples that follow are considerably smaller than many &quot;real world&quot; samples (under 1K rows).</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="healthcare-use-case-diabetes-prediction">HealthCare Use Case: Diabetes Prediction<a href="#healthcare-use-case-diabetes-prediction" class="hash-link" aria-label="Direct link to HealthCare Use Case: Diabetes Prediction" title="Direct link to HealthCare Use Case: Diabetes Prediction" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-scan">The Scan<a href="#the-scan" class="hash-link" aria-label="Direct link to The Scan" title="Direct link to The Scan" translate="no">​</a></h3>
<ul>
<li class="">
<p><strong>Use Case</strong>: Predicting a diagnosis of type 2 diabetes</p>
</li>
<li class="">
<p><strong>Models</strong>: Support Vector Classifier (SVC), Multi-layer Perceptron Classifier (MLPC), Logistic Regression (LR), and Decision Tree (DT)</p>
</li>
<li class="">
<p><strong>Trust Factors</strong>: Performance metric, robustness, and explainability, ATX (AI Trust Index).</p>
</li>
<li class="">
<p><strong>Dataset</strong>: Pima Indian women</p>
<p><strong>NOTE</strong>: Fairness was not included in this evaluation because the dataset used was for a homogeneous demographic</p>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="evaluation-overview">Evaluation Overview<a href="#evaluation-overview" class="hash-link" aria-label="Direct link to Evaluation Overview" title="Direct link to Evaluation Overview" translate="no">​</a></h3>
<p>The image below shows the Evaluation overview results as shown in the Certifai Console.</p>
<p>The Evaluation view for each of the identified trust factors is displayed.</p>
<p>Scores are calculated as a percent (out of 100%) for each trust factor and model.</p>
<p>The higher the score, the better the model performed for the given trust factor.</p>
<p><img decoding="async" loading="lazy" alt="Healthcare: Diabetes Evaluation Overview" src="/documentarian/assets/images/interp-healthcare-eval-overview-4913d3e2b2ac9d3efec006ea4d7c6c67.png" width="2726" height="1118" class="img_ev3q"></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="interpret-robustness">Interpret Robustness<a href="#interpret-robustness" class="hash-link" aria-label="Direct link to Interpret Robustness" title="Direct link to Interpret Robustness" translate="no">​</a></h3>
<p><strong>Observations</strong></p>
<ul>
<li class="">Greater variation in the robustness scores (heights of the bars)</li>
<li class="">Lower scores for robustness - All of the models have under 50% robustness.</li>
<li class="">The multi-layer perceptron (MLPC) and decision tree (DT) models have much lower robustness scores.</li>
</ul>
<p><strong>Conclusions</strong>:</p>
<ul>
<li class="">A low value of robustness arises because the majority of the data points and their counterfactuals are close to the decision boundary. This often occurs when there is a complex decision boundary, which is common when a model is overfitted.</li>
<li class="">This dataset does not provide a clear separation of those who have  diabetes and those who don&#x27;t.</li>
<li class="">The MLPC and DT models may be overfitted.</li>
</ul>
<p><strong>Actions</strong>:</p>
<ul>
<li class="">Based on the robustness results and the early-development state of the models, it would make sense to revisit the tuning of the models.</li>
<li class="">Check MLPC and DT models&#x27; accuracy scores against the training dataset versus the test dataset to confirm that the models are overfitted.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="interpret-explainability">Interpret Explainability<a href="#interpret-explainability" class="hash-link" aria-label="Direct link to Interpret Explainability" title="Direct link to Interpret Explainability" translate="no">​</a></h3>
<p>The following view from the Console displays the explainability histogram for each model, which shows the percentage of explanations that require a given number of changed features. In general, the fewer features in the counterfactual explanation, the simpler it is for a human to understand the explanation.</p>
<p><img decoding="async" loading="lazy" alt="Healthcare: Diabetes Evaluation Explainability" src="/documentarian/assets/images/interp-healthcare-expl-by-model-e486d58ad3a9f76cef93bc562b6bf723.png" width="2656" height="2952" class="img_ev3q"></p>
<p><strong>Observations</strong>:</p>
<ul>
<li class="">The explainability figures are high for all of the models</li>
<li class="">Most of the models&#x27; predictions can be explained by a change in only one or two features</li>
</ul>
<p><strong>Conclusion</strong>:</p>
<ul>
<li class="">All models have simple counterfactual explanations.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="interpret-explanations">Interpret Explanations<a href="#interpret-explanations" class="hash-link" aria-label="Direct link to Interpret Explanations" title="Direct link to Interpret Explanations" translate="no">​</a></h3>
<p>In addition to displaying the model&#x27;s overall explainability score, the Console provides a set of sample explanations that you can click through one at a time to explore the details. This can offer insights into the model.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="decision-tree-model-explanations">Decision Tree model explanations<a href="#decision-tree-model-explanations" class="hash-link" aria-label="Direct link to Decision Tree model explanations" title="Direct link to Decision Tree model explanations" translate="no">​</a></h4>
<p>The explanation detail (#8) below displays the observations for the  decision tree (DT) model.</p>
<p><img decoding="async" loading="lazy" alt="Healthcare: Diabetes Counterfactual Explanation 8 for Decision Tree model" src="/documentarian/assets/images/interp-healthcare-expl-obs8-DT-8824442c973915fe1c9c0f4b81977106.png" width="2736" height="1356" class="img_ev3q"></p>
<p><strong>Observation</strong>:</p>
<ul>
<li class="">The model predicts that a subject with a glucose level of 155 does not have diabetes, and one with exactly the same other feature values and a glucose level of 154 does have diabetes.</li>
</ul>
<p><strong>Conclusion</strong>:</p>
<ul>
<li class="">The model behavior seems questionable because typically, with a higher level of glucose a subject is more likely to have diabetes.</li>
<li class="">The oddity is almost certainly related to overfitting.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="logistic-regression-model-explanations">Logistic Regression model explanations<a href="#logistic-regression-model-explanations" class="hash-link" aria-label="Direct link to Logistic Regression model explanations" title="Direct link to Logistic Regression model explanations" translate="no">​</a></h4>
<p>The explanation detail (#8) below shows the same observation for the logistic regression (LR) model.</p>
<p><img decoding="async" loading="lazy" alt="Healthcare: Diabetes Counterfactual Explanation 8 for Logistic Regression model" src="/documentarian/assets/images/interp-healthcare-expl-obs8-LR-afc3b171dae8ad6969bc0b51e37c1a97.png" width="2736" height="1448" class="img_ev3q"></p>
<p><strong>Observation</strong>:</p>
<ul>
<li class="">The LR model behavior predicts that the subject with a glucose level of 155 has diabetes, whereas a subject with the same features except for a lower glucose and slightly lower BMI index does not.</li>
</ul>
<p><strong>Conclusion</strong>:</p>
<ul>
<li class="">The LR model is explanation is not problematic, which makes it a better choice.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="possible-use-case-conclusions">Possible Use Case Conclusions<a href="#possible-use-case-conclusions" class="hash-link" aria-label="Direct link to Possible Use Case Conclusions" title="Direct link to Possible Use Case Conclusions" translate="no">​</a></h3>
<ul>
<li class="">If the MLPC and DT models could not be improved, the combination of their lack of robustness and weaker performance would discount them from selection.</li>
<li class="">Because the LR model scores better for performance, explainability, and robustness, it is the preferred model.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="banking-use-case-loan-decision">Banking Use Case: Loan Decision<a href="#banking-use-case-loan-decision" class="hash-link" aria-label="Direct link to Banking Use Case: Loan Decision" title="Direct link to Banking Use Case: Loan Decision" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-scan-1">The Scan<a href="#the-scan-1" class="hash-link" aria-label="Direct link to The Scan" title="Direct link to The Scan" translate="no">​</a></h3>
<ul>
<li class=""><strong>Use Case</strong>: Banking use case determining loan approval/denial</li>
<li class=""><strong>Models</strong>: Support Vector Classifier (SVC), Multi-layer Perceptron Classifier (MLPC), Logistic Regression (LR), and Decision Tree (DT)</li>
<li class=""><strong>Trust Factors</strong>: Performance metric, robustness, explainability, AI Trust Index (ATX), and fairness<!-- -->
<ul>
<li class="">Fairness sensitive features defined:<!-- -->
<ul>
<li class="">Age: &lt; 25 years old and &gt;= 25 years old</li>
<li class="">Status: a combination of marital status and gender (e.g. male and single).</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="evaluation-overview-1">Evaluation Overview<a href="#evaluation-overview-1" class="hash-link" aria-label="Direct link to Evaluation Overview" title="Direct link to Evaluation Overview" translate="no">​</a></h3>
<p>The image below shows the Evaluation overview results as shown in the Certifai Console.</p>
<p>The Evaluation view for each of the identified trust factors is displayed.</p>
<p>Scores are calculated as a percent (out of 100%) for each trust factor and model, plus the ATX (AI Trust Index).</p>
<p>The higher the score, the better the model performed for the given trust factor.</p>
<p><img decoding="async" loading="lazy" alt="Banking Approval Evaluation Overview" src="/documentarian/assets/images/interp-banking-eval-overview-3adcb9f5e1c274a78dd273bc89790acc.png" width="2736" height="1142" class="img_ev3q"></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="interpret-robustness-1">Interpret Robustness<a href="#interpret-robustness-1" class="hash-link" aria-label="Direct link to Interpret Robustness" title="Direct link to Interpret Robustness" translate="no">​</a></h3>
<p><strong>Observations</strong>:</p>
<ul>
<li class="">The DT model has significantly lower robustness.</li>
<li class="">The LR model where regularization has been used to counter overfitting shows a higher robustness score.</li>
</ul>
<p><strong>Conclusion</strong>:</p>
<ul>
<li class="">The DT model may suffer from overfitting.</li>
<li class="">The best selection would be the LR model.</li>
<li class="">A second choice might be improve the decision tree model  (e.g. by using regularization techniques) to discourage overfitting.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="interpret-fairness">Interpret Fairness<a href="#interpret-fairness" class="hash-link" aria-label="Direct link to Interpret Fairness" title="Direct link to Interpret Fairness" translate="no">​</a></h3>
<p>The Fairness details display provides a view into potential bias of the models.</p>
<p>The upper chart compares the fairness scores for age and status, the two defined sensitive features for fairness in this use case.</p>
<p>The lower chart shows the burden associated with the groups within the status feature.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="support-vector-classifier-model-fairness">Support Vector Classifier model fairness<a href="#support-vector-classifier-model-fairness" class="hash-link" aria-label="Direct link to Support Vector Classifier model fairness" title="Direct link to Support Vector Classifier model fairness" translate="no">​</a></h4>
<p>The following charts are for the SVC model:</p>
<p><img decoding="async" loading="lazy" alt="Banking Approval Fairness Support Vector Classifier" src="/documentarian/assets/images/interp-banking-fairness-SVC-e0afdb3466642170c44544520708bbaa.png" width="2736" height="1434" class="img_ev3q"></p>
<p><strong>Observations</strong>:</p>
<ul>
<li class="">The SVC model is the most biased model with a fairness score of 70%.</li>
<li class="">(Upper chart) The score for status is lower (i.e. less fair) than that for age.</li>
<li class="">(Lower chart) The lowest burden is on married males.</li>
<li class="">Three times more burden is on divorced males.</li>
<li class="">The difference in burdens (change needed to obtain a favorable outcome) is greater across the status groups than the age groups</li>
</ul>
<p><strong>Conclusion</strong>:</p>
<ul>
<li class="">According to the SVC model, divorced males would need to make larger changes in order to have a loan approved.</li>
</ul>
<p><strong>Actions</strong>:</p>
<ul>
<li class="">If a model has a low fairness score, you might check to see
if the data is imbalanced, and if it is, gather additional data.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="multi-layer-perceptron-classifier-model-fairness">Multi-layer Perceptron Classifier model fairness<a href="#multi-layer-perceptron-classifier-model-fairness" class="hash-link" aria-label="Direct link to Multi-layer Perceptron Classifier model fairness" title="Direct link to Multi-layer Perceptron Classifier model fairness" translate="no">​</a></h4>
<p>The following charts are for the MLPC model:</p>
<p><img decoding="async" loading="lazy" alt="Banking Approval Fairness MLPC" src="/documentarian/assets/images/interp-banking-fairness-MLPC-aacd7b22a2ac69baac340a638ead4055.png" width="2736" height="1358" class="img_ev3q"></p>
<p><strong>Observations</strong>:</p>
<ul>
<li class="">The MLPC model has similar fairness for both age and status.</li>
<li class="">The burdens across groups are significantly more equal (than those for the SVC model)</li>
</ul>
<p><strong>Conclusion</strong>:</p>
<ul>
<li class="">The MLPC model is more fair than the SVC model.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="interpret-explainability-1">Interpret Explainability<a href="#interpret-explainability-1" class="hash-link" aria-label="Direct link to Interpret Explainability" title="Direct link to Interpret Explainability" translate="no">​</a></h3>
<p>The following view from the Console shows the explainability histogram for each model.</p>
<p>The histograms in this view show the percentage of explanations that require a given number of changed features.</p>
<p>The fewer features in the counterfactual explanation, the simpler it is for a human to understand the explanation.</p>
<p><img decoding="async" loading="lazy" alt="Banking Approval Evaluation Explainability" src="/documentarian/assets/images/interp-banking-expl-by-model-d945ef023b3ad586992b02cb92e30bfb.png" width="2700" height="3092" class="img_ev3q"></p>
<p><strong>Observation</strong>:</p>
<ul>
<li class="">The MLPC model has reasonably high explainability with most predictions explained by a change in only one or two features.</li>
<li class="">The SVC model has lower explainability as it often requires three or four changed features to explain a prediction.</li>
</ul>
<p><strong>Conclusion</strong>:</p>
<ul>
<li class="">MLPC is the better model to choose from point of view of explainability, if its other trust factor scores are acceptable. (In this case the robustness score is also high)</li>
<li class="">The higher-performing SVC model may be harder for a human to understand, which is unfavorable.</li>
</ul>
<p><strong>Actions</strong></p>
<ul>
<li class="">Try another model implementation, specifically one
with lower complexity (e.g. in a classification setting, try logistic
regression).</li>
<li class="">Try adding or increasing the amount of regularization in
your model.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="interpret-explanations-1">Interpret Explanations<a href="#interpret-explanations-1" class="hash-link" aria-label="Direct link to Interpret Explanations" title="Direct link to Interpret Explanations" translate="no">​</a></h3>
<p>The interpretation of explanations depends on how the explanation dataset has been sampled. For example, you could:</p>
<ul>
<li class="">Explore the model behavior by deliberately choosing inputs that are potential outliers</li>
<li class="">Choose a random sample to facilitate discussion with domain experts to build confidence in an algorithm and look for unexpected results</li>
<li class="">Choose a larger representative sample (e.g. 1000 rows) to perform additional analysis (e.g. This notebook (link to notebook has been removed) is designed understand how frequently various features occur in explanations.)</li>
</ul>
<p>The explanations for this use case have been selected because they are noteworthy and unexpected.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="support-vector-classifier-model-explanations">Support Vector Classifier model explanations<a href="#support-vector-classifier-model-explanations" class="hash-link" aria-label="Direct link to Support Vector Classifier model explanations" title="Direct link to Support Vector Classifier model explanations" translate="no">​</a></h4>
<p>The explanation detail (#29) below shows a counterfactual explanation for a prediction made by the SVC model.</p>
<p><img decoding="async" loading="lazy" alt="Banking Approval Counterfactual Explanation 29 for Support Vector Classifier model" src="/documentarian/assets/images/interp-banking-expl-obs29-SVC-c07bcdd37475d1a8dc506e3cb82d0281.png" width="2736" height="1684" class="img_ev3q"></p>
<p><strong>Observation</strong>:</p>
<ul>
<li class="">The SVC model requires four changed features to alter the prediction (checking status, duration of loan, history of paying back loans, and employment period).</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="multi-layer-perceptron-classifier-model-explanations">Multi-layer Perceptron Classifier model explanations<a href="#multi-layer-perceptron-classifier-model-explanations" class="hash-link" aria-label="Direct link to Multi-layer Perceptron Classifier model explanations" title="Direct link to Multi-layer Perceptron Classifier model explanations" translate="no">​</a></h4>
<p>The explanation detail (#29) below shows a counterfactual explanation for a prediction made by the MLPC model.</p>
<p><img decoding="async" loading="lazy" alt="Banking Approval Counterfactual Explanation 29 for Multi-Layer Perceptron Classifier model" src="/documentarian/assets/images/interp-banking-expl-obs29-MLPC-244a22a31c2a3585d7928c95f8c7e7f7.png" width="2736" height="1452" class="img_ev3q"></p>
<p><strong>Observation</strong>:</p>
<ul>
<li class="">The MLPC model requires two changed features to alter the prediction (reduced residence time and increased number of existing cards would cause loan to be denied).</li>
</ul>
<p><strong>Conclusion</strong>:</p>
<ul>
<li class="">The MLPC model&#x27;s counterfactual is simpler to understand because it requires fewer changed features to alter the result.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="possible-use-case-conclusions-1">Possible Use Case Conclusions<a href="#possible-use-case-conclusions-1" class="hash-link" aria-label="Direct link to Possible Use Case Conclusions" title="Direct link to Possible Use Case Conclusions" translate="no">​</a></h3>
<p>If the comparison scan is run with the purpose of choosing between existing models that cannot be retrained or modified:</p>
<ul>
<li class="">The lower performance and lower robustness of the DT model would make it the weakest candidate, despite its higher fairness and explainability scores.</li>
<li class="">If the selection of a model is based only on the performance metric, the SVC model is the best candidate, even though it has the lowest fairness score.</li>
<li class="">If the selection of a model is based only on the ATX score, the MLPC model is the best candidate (when the scores are all weighted equally).</li>
<li class="">If the selection of a model is based only on the ATX score that weighs explainability lower and performance higher, the LR model is the best candidate.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="general-interpretation-conclusions">General Interpretation Conclusions<a href="#general-interpretation-conclusions" class="hash-link" aria-label="Direct link to General Interpretation Conclusions" title="Direct link to General Interpretation Conclusions" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="fairness">Fairness<a href="#fairness" class="hash-link" aria-label="Direct link to Fairness" title="Direct link to Fairness" translate="no">​</a></h3>
<ul>
<li class="">The fairness score won&#x27;t tell you if there are underrepresented groups.</li>
<li class="">However, if Certifai has a low fairness score, then you could check to see if the data is imbalanced, and if it is, gather more data</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="explainability">Explainability<a href="#explainability" class="hash-link" aria-label="Direct link to Explainability" title="Direct link to Explainability" translate="no">​</a></h3>
<p>If the number of counterfactuals required to change the outcome is high and the model is therefore less explainable:</p>
<ul>
<li class="">Try another model implementation, specifically one
with lower complexity (e.g. in a classification setting, try logistic
regression).</li>
<li class="">Try adding or increasing the amount of regularization in
your model.</li>
</ul></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/documentarian/docs/tutorial-extras/ceritfai-basics/factors/robustness"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Robustness</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/documentarian/docs/tutorial-extras/kubernetes-installation"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Kubernetes Installation</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#assumptions" class="table-of-contents__link toc-highlight">Assumptions</a></li><li><a href="#healthcare-use-case-diabetes-prediction" class="table-of-contents__link toc-highlight">HealthCare Use Case: Diabetes Prediction</a><ul><li><a href="#the-scan" class="table-of-contents__link toc-highlight">The Scan</a></li><li><a href="#evaluation-overview" class="table-of-contents__link toc-highlight">Evaluation Overview</a></li><li><a href="#interpret-robustness" class="table-of-contents__link toc-highlight">Interpret Robustness</a></li><li><a href="#interpret-explainability" class="table-of-contents__link toc-highlight">Interpret Explainability</a></li><li><a href="#interpret-explanations" class="table-of-contents__link toc-highlight">Interpret Explanations</a></li><li><a href="#possible-use-case-conclusions" class="table-of-contents__link toc-highlight">Possible Use Case Conclusions</a></li></ul></li><li><a href="#banking-use-case-loan-decision" class="table-of-contents__link toc-highlight">Banking Use Case: Loan Decision</a><ul><li><a href="#the-scan-1" class="table-of-contents__link toc-highlight">The Scan</a></li><li><a href="#evaluation-overview-1" class="table-of-contents__link toc-highlight">Evaluation Overview</a></li><li><a href="#interpret-robustness-1" class="table-of-contents__link toc-highlight">Interpret Robustness</a></li><li><a href="#interpret-fairness" class="table-of-contents__link toc-highlight">Interpret Fairness</a></li><li><a href="#interpret-explainability-1" class="table-of-contents__link toc-highlight">Interpret Explainability</a></li><li><a href="#interpret-explanations-1" class="table-of-contents__link toc-highlight">Interpret Explanations</a></li><li><a href="#possible-use-case-conclusions-1" class="table-of-contents__link toc-highlight">Possible Use Case Conclusions</a></li></ul></li><li><a href="#general-interpretation-conclusions" class="table-of-contents__link toc-highlight">General Interpretation Conclusions</a><ul><li><a href="#fairness" class="table-of-contents__link toc-highlight">Fairness</a></li><li><a href="#explainability" class="table-of-contents__link toc-highlight">Explainability</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Links</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/suemich/" target="_blank" rel="noopener noreferrer" class="footer__link-item">My LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.susan-michalski.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">My Author Website<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>