<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-cool-stuff/primer" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Certifai Algorithm Primer | Susan Michalski - Documentation Specialist</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://smichalski17-dev.github.io/documentarian/img/typwriter.jpg"><meta data-rh="true" name="twitter:image" content="https://smichalski17-dev.github.io/documentarian/img/typwriter.jpg"><meta data-rh="true" property="og:url" content="https://smichalski17-dev.github.io/documentarian/docs/cool-stuff/primer"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Certifai Algorithm Primer | Susan Michalski - Documentation Specialist"><meta data-rh="true" name="description" content="This page is an informational primer on how the algorithms work in the Certifai application.
"><meta data-rh="true" property="og:description" content="This page is an informational primer on how the algorithms work in the Certifai application.
"><link data-rh="true" rel="canonical" href="https://smichalski17-dev.github.io/documentarian/docs/cool-stuff/primer"><link data-rh="true" rel="alternate" href="https://smichalski17-dev.github.io/documentarian/docs/cool-stuff/primer" hreflang="en"><link data-rh="true" rel="alternate" href="https://smichalski17-dev.github.io/documentarian/docs/cool-stuff/primer" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Cool Stuff","item":"https://smichalski17-dev.github.io/documentarian/docs/category/cool-stuff"},{"@type":"ListItem","position":2,"name":"Certifai Algorithm Primer","item":"https://smichalski17-dev.github.io/documentarian/docs/cool-stuff/primer"}]}</script><link rel="alternate" type="application/rss+xml" href="/documentarian/blog/rss.xml" title="Susan Michalski - Documentation Specialist RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/documentarian/blog/atom.xml" title="Susan Michalski - Documentation Specialist Atom Feed"><link rel="stylesheet" href="/documentarian/assets/css/styles.6d484712.css">
<script src="/documentarian/assets/js/runtime~main.9d40e250.js" defer="defer"></script>
<script src="/documentarian/assets/js/main.ce0b64b7.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/documentarian/img/avatar.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/documentarian/"><div class="navbar__logo"><img src="/documentarian/img/avatar.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/documentarian/img/avatar.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/documentarian/docs/intro">Documentation</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/documentarian/docs/intro"><span title="Documentaion Samples" class="linkLabel_WmDU">Documentaion Samples</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/documentarian/docs/category/about-me"><span title="About Me" class="categoryLinkLabel_W154">About Me</span></a><button aria-label="Expand sidebar category &#x27;About Me&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/documentarian/docs/category/documents"><span title="Documents" class="categoryLinkLabel_W154">Documents</span></a><button aria-label="Expand sidebar category &#x27;Documents&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/documentarian/docs/category/templates"><span title="Templates" class="categoryLinkLabel_W154">Templates</span></a><button aria-label="Expand sidebar category &#x27;Templates&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/documentarian/docs/category/cool-stuff"><span title="Cool Stuff" class="categoryLinkLabel_W154">Cool Stuff</span></a><button aria-label="Collapse sidebar category &#x27;Cool Stuff&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/documentarian/docs/cool-stuff/documentation-style-guide"><span title="Documentaiton Style Guide" class="linkLabel_WmDU">Documentaiton Style Guide</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/documentarian/docs/cool-stuff/jira-story-checklist"><span title="Jira Story Writing Checklist" class="linkLabel_WmDU">Jira Story Writing Checklist</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/documentarian/docs/cool-stuff/primer"><span title="Certifai Algorithm Primer" class="linkLabel_WmDU">Certifai Algorithm Primer</span></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/documentarian/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/documentarian/docs/category/cool-stuff"><span>Cool Stuff</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Certifai Algorithm Primer</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Certifai Algorithm Primer</h1></header><p>This page is an informational primer on how the algorithms work in the Certifai application.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview" translate="no">​</a></h2>
<p>Certifai is a risk assessment tool that repeatedly probes a predictive model M in terms of its input-output behavior and provides an
evaluation of model risk along 3 dimensions:</p>
<ul>
<li class="">Robustness (R)</li>
<li class="">Explainability (E)</li>
<li class="">Fairness/Bias (F).</li>
</ul>
<p>It treats the model M as a black
box - thus it only needs to know the model’s response or output corresponding to a given instance or input. This means that any kind
of predictive model can be assessed, including rule-based systems, statistical approaches, and neural networks. Certifai can be used to
assess regression as well as classification models (binary and multi-class) models. However, its application in a binary classification setting
is the easiest to understand and is briefly described below.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="certifai-for-binary-classifiers">Certifai for Binary Classifiers<a href="#certifai-for-binary-classifiers" class="hash-link" aria-label="Direct link to Certifai for Binary Classifiers" title="Direct link to Certifai for Binary Classifiers" translate="no">​</a></h2>
<p>Without loss of generality, we refer to the two classes as the
positive and negative class respectively, with the positive class
being a more desired outcome. As a running example, we
consider a loan approval case, in which each instance is a loan
application, the positive class is “approved” and the negative
class is “denied”. Any classifier will partition the input space into
regions that are assigned the same class label, separated by
decision boundaries.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="counterfactuals">Counterfactuals<a href="#counterfactuals" class="hash-link" aria-label="Direct link to Counterfactuals" title="Direct link to Counterfactuals" translate="no">​</a></h2>
<p>Certifai is based on the notion of a counterfactual (CF), as used
in the recent fairness literature, e.g., Wachter et al., 2017 [1] and
Google’s What-if Tool [2]. Given an instance, a CF is a data-point
for which the classifier returns a different class label. The most
relevant CFs are those that are as close as possible to the given
instance. Then, the difference between the feature vectors
representing the probe and its corresponding CF represents the
(minimal) change that needs to be made to the probe in order
to flip the outcome. Given an input instance (the “probe”) and
a black-box classifier, Certifai generates a series of (synthetic)
instances based on a genetic algorithm, to efficiently query the
model and estimate the location of the CF that is nearest to the
probe. We use the L1 distance metric and induce a sparsity prior
as well so that a CF tends to not differ from the probe in many
attributes. These properties make the CF more explainable and
actionable, as explained later.</p>
<p>Note that the CF depends on the given probe as well as the
given model M. We guarantee that the model will return the
opposite class label for the CF. Moreover, while in general it is not
possible to guarantee (given limited compute time) that the CF
is the closest possible, the CFs that Certifai finds are in general
substantially closer than those from alternative approaches,
including the one taken by Google [2], which restricts the CF to
be an actual data point in the evaluation dataset. Moreover, the
user can specify domain constraints to ensure that the
CF is realistic. For example, in a medical application, the user
can specify that demographics (gender, ethnicity) of an instance
cannot change, but only behaviors and treatments (exercise,
medications) can change in the CF. Additionally, Certifai
has the option of returning multiple CFs, representing
qualitatively disparate options, all of which lead to a different
outcome.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="risk-evaluation-using-counterfactuals">Risk Evaluation Using Counterfactuals<a href="#risk-evaluation-using-counterfactuals" class="hash-link" aria-label="Direct link to Risk Evaluation Using Counterfactuals" title="Direct link to Risk Evaluation Using Counterfactuals" translate="no">​</a></h2>
<p>Robustness (R), Explainability (E) and Fairness/Bias (F) are all joint
properties of the model being assessed, as well as the application
the model has been designed for. A proper evaluation thus
requires an evaluation dataset, D, that is representative of the
application of interest. For each instance in this dataset, Certifai
determines a suitable CF. All the CFs thus determined then
contribute to the model risk evaluation as follows:</p>
<ul>
<li class=""><strong>Robustness</strong>: The distance of a CF to the corresponding
probe point, averaged over D, is a measure of robustness or sensitivity, since it indicates the average amount of
(adversarial) perturbation needed to flip the outcome.
Higher scores indicate less sensitive or more robust
models. Scores can also be normalized to a range from 0 to
100 using a proprietary non-linear but monotonic function
of the CF distance after normalization w.r.t intra-class data
spreads.</li>
<li class=""><strong>Explainability</strong>: A CF can be expressed in terms of the
number of attributes that need to change in order to flip
the outcome. Fewer attributes changing means that the
explanation on what it will minimally take to change the
outcome (for example to convert an application from
denied to accepted status) is more succinct and hence
more explainable. Each CF gets a explainability score
that is a monotonically decreasing function of the number
of attributes involved in the change vector. The mean
explainability score is a measure of the explainability of
the entire model, normalized to a range from 0 to 100. In
addition to the model-level explainability, if CF individual
explanations are needed for specific probes or instances,
such instances can be collated and specified in an
“explanation dataset”.</li>
<li class=""><strong>Fairness/Bias</strong>: For fairness studies, one has to first define
one or more categorical variables, called the grouping
feature(s) (aka protected attribute(s)), which is used to
partition the instances into subgroups. For example, the
groupings can be based on gender, ethnicity, a combination
of gender and age, etc. Then, fairness is evaluated by
comparing the outcomes or burden imposed by the model
across the different subgroups. For a two-class problem,
we consider the burden to be zero for a given instance if
it receives the desired outcome (positive class). Otherwise
the burden is indicated by the difficulty of recourse required
to flip the outcome from negative to positive, as measured
by the corresponding CF distance. Finally, the average
burden across the different subgroups is compared using
the gini index, a popular measure of inequality. A score of 100 means that each group has the same average burden,
while a score of 0 means that one subgroup has all the
burden while other groups have no burden at all.</li>
</ul>
<p>It is well known that there are many indicators of fairness
and different notions of justice, such as distributional justice
and procedural justice. Machine learning based fairness
assessments (e.g. demographic parity, equalized odds) typically
focus on distributive justice and consider only binary outcomes.
Our approach is more nuanced, since it considers not only the
outcome but also how difficult it is to attain a more preferred
outcome.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="extensions-to-regression-settings">Extensions to Regression Settings<a href="#extensions-to-regression-settings" class="hash-link" aria-label="Direct link to Extensions to Regression Settings" title="Direct link to Extensions to Regression Settings" translate="no">​</a></h2>
<p>For regression, an alternate outcome can be defined in terms of
relative or absolute thresholds of the predicted value, depending
on the application. For example, if the current model produces
a function f(x), then two derived functions, f(x) + λσ and f(x) - λσ
can serve as upper and lower boundaries respectively, where
λ is a user defined value, and σ is the standard deviation of the
outcome. Alternatively, if one is predicting a credit score, then
a fixed value, say 650 for FICO, can be specified, such at any
score above this value is deemed as desirable. Thus we split
the outcome in two or three regimes, “current”, “higher” and
“lower”, depending on one or two boundaries being specified,
converting it into a binary or 3-class problem.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References" translate="no">​</a></h2>
<ol>
<li class="">Sandra Wachter, Brent Mittelstadt, and Chris Russell.
Counterfactual explanations without opening the black box:
automated decisions and the GDPR. Harvard Journal of Law
&amp; Technology, 31(2):2018, 2017</li>
<li class=""><a href="https://pair-code.github.io/what-if-tool/" target="_blank" rel="noopener noreferrer" class="">https://pair-code.github.io/what-if-tool/</a></li>
<li class=""><a href="https://plato.stanford.edu/entries/causation-counterfactual/" target="_blank" rel="noopener noreferrer" class="">https://plato.stanford.edu/entries/causation-counterfactual/</a></li>
</ol></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/documentarian/docs/cool-stuff/jira-story-checklist"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Jira Story Writing Checklist</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a></li><li><a href="#certifai-for-binary-classifiers" class="table-of-contents__link toc-highlight">Certifai for Binary Classifiers</a></li><li><a href="#counterfactuals" class="table-of-contents__link toc-highlight">Counterfactuals</a></li><li><a href="#risk-evaluation-using-counterfactuals" class="table-of-contents__link toc-highlight">Risk Evaluation Using Counterfactuals</a></li><li><a href="#extensions-to-regression-settings" class="table-of-contents__link toc-highlight">Extensions to Regression Settings</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Links</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/suemich/" target="_blank" rel="noopener noreferrer" class="footer__link-item">My LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.susan-michalski.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">My Author Website<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>